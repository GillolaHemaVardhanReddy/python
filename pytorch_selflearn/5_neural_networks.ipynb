{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† 1Ô∏è‚É£ What‚Äôs a ‚Äúneuron‚Äù mathematically?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single neuron performs this:\n",
    "\n",
    "[\n",
    "y = w.x + b\n",
    "]\n",
    "\n",
    "where\n",
    "\n",
    "* **x** = input(s)\n",
    "* **w** = weight(s)\n",
    "* **b** = bias\n",
    "* **y** = output (predicted value)\n",
    "\n",
    "During training, we adjust **w** and **b** so that  \n",
    "\n",
    "( y_pred ) gets close to ( y_true ).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚öôÔ∏è 2Ô∏è‚É£ What happens during learning?\n",
    "\n",
    "If your data has an actual pattern ‚Äî say\n",
    "\n",
    "y_true =2x+1\n",
    " \n",
    "‚Äî your neuron starts with random w and b,  \n",
    "\n",
    "and gradually adjusts them until its predictions match that rule.\n",
    "\n",
    "It learns those values by looking at how wrong it is (the loss)  \n",
    "\n",
    "and using gradients to make itself less wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Data\n",
    "\n",
    "We make fake data following a simple rule \n",
    "\n",
    "y=2x+1, with small noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.linspace(0, 10, 100).unsqueeze(1)   # 100 data points between 0 and 10\n",
    "y_true = 2*X + 1 + 0.5*torch.randn(X.size())  # real output + some random noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* torch.linspace(0,10,100) ‚Üí gives 100 evenly spaced numbers between 0 and 10 (like x=0,0.1,‚Ä¶10)\n",
    "\n",
    "* .unsqueeze(1) ‚Üí changes shape from [100] ‚Üí [100,1] (100 rows, 1 column)\n",
    "\n",
    "* torch.randn(X.size()) ‚Üí adds random noise (simulating imperfect data)\n",
    "\n",
    "| x   | y_true |\n",
    "| --- | ------ |\n",
    "| 0.0 | ‚âà 1.0  |\n",
    "| 1.0 | ‚âà 3.1  |\n",
    "| 2.0 | ‚âà 4.9  |\n",
    "| ... | ...    |\n",
    "\n",
    "\n",
    "Step 2: Create the neuron\n",
    "\n",
    "In math:\n",
    "\n",
    "y_pred =w‚ãÖx+b\n",
    "\n",
    "In PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Linear(in_features=1, out_features=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* nn.Linear is PyTorch‚Äôs ready-made single neuron class.  \n",
    "\n",
    "It automatically creates:\n",
    "\n",
    "* a weight (w) parameter of shape [1,1]\n",
    "\n",
    "* a bias (b) parameter of shape [1]\n",
    "\n",
    "these are randomly assigned weight and bias \n",
    "\n",
    "check them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.4607]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.9634], requires_grad=True)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define how it learns\n",
    "\n",
    "To train, we need two things:\n",
    "\n",
    "1Ô∏è‚É£ Loss function ‚Äî how wrong the neuron‚Äôs prediction is  \n",
    "\n",
    "2Ô∏è‚É£ Optimizer ‚Äî how we update weights based on gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()                 # Mean Squared Error loss = (y_pred - y_true)^2\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)  # learning rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meaning:\n",
    "\n",
    "If predictions are far off ‚Üí big loss ‚Üí bigger weight updates\n",
    "\n",
    "If predictions are close ‚Üí small loss ‚Üí small updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Training = the feedback loop\n",
    "\n",
    "Each epoch = one pass through all your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Loss = 0.2206\n",
      "Epoch 80, Loss = 0.2182\n",
      "Epoch 120, Loss = 0.2166\n",
      "Epoch 160, Loss = 0.2155\n",
      "Epoch 200, Loss = 0.2147\n"
     ]
    }
   ],
   "source": [
    "X = torch.linspace(0, 10, 100).unsqueeze(1)   # 100 data points between 0 and 10\n",
    "y_true = 2*X + 1 + 0.5*torch.randn(X.size())  # real output + some random noise\n",
    "\n",
    "model = torch.nn.Linear(in_features=1, out_features=1)\n",
    "\n",
    "criterion = torch.nn.MSELoss()                 # Mean Squared Error loss = (y_pred - y_true)^2\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)  # learning rate = 0.01\n",
    "\n",
    "for epoch in range(200):\n",
    "    # 1. Forward pass: neuron computes y_pred = w*x + b\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    # 2. Compute error between prediction and actual value\n",
    "    loss = criterion(y_pred, y_true)\n",
    "    \n",
    "    # 3. Backward pass: calculate gradients\n",
    "    optimizer.zero_grad()  # clears old gradients\n",
    "    loss.backward()        # autograd computes ‚àÇLoss/‚àÇw and ‚àÇLoss/‚àÇb\n",
    "    \n",
    "    # 4. Update weights and bias\n",
    "    optimizer.step()       # w = w - lr * grad_w, b = b - lr * grad_b\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch+1) % 40 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Loss = {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned weight: 2.019040822982788\n",
      "Learned bias: 0.8522976636886597\n"
     ]
    }
   ],
   "source": [
    "\n",
    "[w, b] = model.parameters()\n",
    "print(\"Learned weight:\", w.item())\n",
    "print(\"Learned bias:\", b.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so small doubts are:\n",
    "1. why did we use param_new = param_old - learn_rate * derivativeOf(y_pred_function - loss_function)? is that because it just worked well for learning after trying different kinds of equations or anything specific reason?   \n",
    "\n",
    "2. why did we use learning rate?  \n",
    "\n",
    "3. why only derivative why not just any other ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† 1Ô∏è‚É£ Why do we use\n",
    "\n",
    "[\n",
    "param_new = param_old - neta * derivative(param)\n",
    "]\n",
    "instead of some other formula?\n",
    "\n",
    "This equation is the core of **gradient descent**, and it comes straight from calculus.\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Think of the loss function as a landscape:\n",
    "\n",
    "* Every parameter (like `w`, `b`) is an **axis** in this landscape.\n",
    "* The **height** at any point = how bad the model is (the loss).\n",
    "\n",
    "So, training is like standing on a mountain and trying to reach the **lowest valley (minimum loss)**.\n",
    "\n",
    "* The **derivative (gradient)** gives you the slope ‚Äî it tells you:\n",
    "\n",
    "  * which direction is *uphill* (increasing loss)\n",
    "  * how steep the slope is\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Why the formula has a minus sign:\n",
    "\n",
    "[\n",
    "param_new = param_old - neta * derivative(param)\n",
    "]\n",
    "\n",
    "* The gradient (\\frac{‚àÇL}{‚àÇparam}) points **uphill** (toward higher loss).\n",
    "* So we move in the **opposite direction** (the negative sign) to go *downhill*.\n",
    "\n",
    "That‚Äôs why it‚Äôs literally called **gradient descent** ‚Äî we ‚Äúdescend‚Äù the slope.\n",
    "\n",
    "---\n",
    "\n",
    "### üßÆ Why this exact equation?\n",
    "\n",
    "It‚Äôs not arbitrary or just ‚Äúbecause it worked.‚Äù\n",
    "It‚Äôs derived from **first-order Taylor approximation** in calculus:\n",
    "\n",
    "If we approximate loss around a small change in parameter:\n",
    "[\n",
    "L(param + Œîparam) ‚âà L(param) + \\frac{‚àÇL}{‚àÇparam} ¬∑ Œîparam\n",
    "]\n",
    "\n",
    "To minimize L, we want to choose (Œîparam) that makes (L) smaller ‚Äî\n",
    "so we move opposite to the gradient:\n",
    "[\n",
    "Œîparam = - Œ∑ ¬∑ \\frac{‚àÇL}{‚àÇparam}\n",
    "]\n",
    "\n",
    "That‚Äôs the mathematically optimal *smallest step* toward minimizing loss in the local neighborhood.\n",
    "\n",
    "So this isn‚Äôt just empirically found ‚Äî it‚Äôs **mathematically justified** from calculus.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è 2Ô∏è‚É£ Why use a learning rate (Œ∑)?\n",
    "\n",
    "The learning rate controls how big each step you take downhill is.\n",
    "\n",
    "Imagine descending a mountain:\n",
    "\n",
    "If you take tiny baby steps (Œ∑ too small) ‚Üí you‚Äôll reach the bottom slowly.\n",
    "\n",
    "If you take huge jumps (Œ∑ too large) ‚Üí you might overshoot or bounce around and never settle.\n",
    "\n",
    "The learning rate (Œ∑) balances:\n",
    "\n",
    "speed of learning\n",
    "\n",
    "stability of convergence\n",
    "\n",
    "That‚Äôs why choosing the right learning rate is crucial in practice.\n",
    "\n",
    "Too small ‚Üí very slow\n",
    "\n",
    "Too big ‚Üí may diverge (loss keeps increasing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üßÆ 3Ô∏è‚É£ Why specifically derivative (gradient) ‚Äî why not just any other method?\n",
    "\n",
    "Excellent question ‚Äî and this goes deep into the philosophy of optimization.\n",
    "\n",
    "We use the derivative because:\n",
    "\n",
    "It tells us exactly how the function is changing with respect to each parameter.\n",
    "\n",
    "It is directional: it tells you the fastest direction to reduce loss.\n",
    "\n",
    "It is mathematically optimal for small steps (proved in optimization theory)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üß≠ Example intuition\n",
    "\n",
    "Imagine you‚Äôre blindfolded in a hilly area, and you can only feel the ground under your feet.\n",
    "\n",
    "The derivative (gradient) tells you where the slope is steepest downward.\n",
    "\n",
    "So following the negative gradient guarantees the fastest descent for that moment.\n",
    "\n",
    "If you moved in any random direction instead, you‚Äôd be guessing blindly.\n",
    "\n",
    "That‚Äôs why the derivative is the most information-efficient way to learn ‚Äî\n",
    "it uses precise calculus instead of trial and error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚öôÔ∏è What about ‚Äúother methods‚Äù?\n",
    "\n",
    "There are advanced variations of gradient descent (like Adam, RMSProp, Adagrad),  \n",
    "\n",
    "but all of them are still built on the same derivative-based foundation ‚Äî  \n",
    "\n",
    "they just modify the step size dynamically or smooth gradients.\n",
    "\n",
    "Even reinforcement learning, meta-learning, or large language model training all depend on gradients ‚Äî  \n",
    "\n",
    "only the source of the loss or how you sample it changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Question                           | Answer                                                                                                                                 |\n",
    "| ---------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Why param = param - lr * grad?** | It‚Äôs derived from calculus: the gradient gives the direction of steepest increase, so we move opposite to minimize loss.               |\n",
    "| **Why learning rate?**             | Controls the step size; too high = unstable, too low = too slow.                                                                       |\n",
    "| **Why derivative?**                | It‚Äôs the mathematically optimal and most efficient way to find the direction of improvement ‚Äî every other method in ML builds on this. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So yes ‚Äî all of deep learning boils down to this calculus truth:\n",
    "\n",
    "The derivative tells us the fastest way to reduce error ‚Äî and the learning rate controls how far we go each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since we used only 2 parameters  \n",
    "\n",
    "we can just have a graph of one param in one axis and other in another axis  \n",
    "\n",
    "since the gradient gives the slope m which has direction if positive then line has angle less than 90 degrees and negative means the slope is greater than 90 degrees  \n",
    "\n",
    "but how does these slopes tell which direction to move so to reduce the loss again?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí• **Beautifully phrased question!**\n",
    "You just stepped into the *geometric heart* of gradient descent ‚Äî how the **sign and size of slopes** tell the model **which direction to move** to reduce the loss.\n",
    "\n",
    "Let‚Äôs go step by step visually and intuitively üëá\n",
    "\n",
    "---\n",
    "\n",
    "# üß≠ 1Ô∏è‚É£ Recap the setup (2 parameters: w and b)\n",
    "\n",
    "Your model:\n",
    "[\n",
    "y_{pred} = w¬∑x + b\n",
    "]\n",
    "\n",
    "Loss:\n",
    "[\n",
    "L(w, b) = \\frac{1}{N}\\sum (w¬∑x_i + b - y_i)^2\n",
    "]\n",
    "\n",
    "This means the **loss** is a function of **two variables**: (w) and (b).\n",
    "\n",
    "So you can imagine a **3D landscape**:\n",
    "\n",
    "* x-axis ‚Üí weight (w)\n",
    "* y-axis ‚Üí bias (b)\n",
    "* z-axis ‚Üí loss (L(w,b))\n",
    "\n",
    "That surface looks like a **bowl** ‚Äî a convex shape ‚Äî because MSE is quadratic.\n",
    "\n",
    "---\n",
    "\n",
    "# üßÆ 2Ô∏è‚É£ The gradient is a 2D arrow (vector)\n",
    "\n",
    "At any point ((w,b)),\n",
    "you can compute the **gradient**:\n",
    "[\n",
    "\\nabla L(w,b) =\n",
    "\\begin{bmatrix}\n",
    "\\frac{‚àÇL}{‚àÇw} \\\n",
    "\\frac{‚àÇL}{‚àÇb}\n",
    "\\end{bmatrix}\n",
    "]\n",
    "\n",
    "This gradient tells us:\n",
    "\n",
    "* **Direction** ‚Üí where the loss increases fastest\n",
    "* **Magnitude** ‚Üí how steep that increase is\n",
    "\n",
    "---\n",
    "\n",
    "# ‚õ∞Ô∏è 3Ô∏è‚É£ The geometric intuition\n",
    "\n",
    "Picture you standing on a hill.\n",
    "You can feel the slope under your feet ‚Äî that‚Äôs the **gradient vector**.\n",
    "\n",
    "* The **gradient direction** points directly **uphill** (toward maximum loss).\n",
    "* The **negative gradient** points **downhill** (toward minimum loss).\n",
    "\n",
    "So to reduce loss, we move:\n",
    "[\n",
    "\\text{new position} = \\text{current position} - Œ∑ √ó \\text{gradient}\n",
    "]\n",
    "That‚Äôs why we subtract ‚Äî we want to go *downhill*.\n",
    "\n",
    "---\n",
    "\n",
    "# üß© 4Ô∏è‚É£ The role of positive/negative slope\n",
    "\n",
    "Let‚Äôs simplify to just **one parameter w** (to visualize slope clearly).\n",
    "\n",
    "Loss curve:\n",
    "Imagine it looks like a ‚ÄúU‚Äù shape ‚Äî the bottom is the best `w`.\n",
    "\n",
    "* **Left side of the bowl:**\n",
    "  The slope ( \\frac{dL}{dw} < 0 ) (gradient negative)\n",
    "  ‚Üí the line slopes **down to the right**\n",
    "  ‚Üí to go *downhill*, you move right (increase `w`)\n",
    "\n",
    "* **Right side of the bowl:**\n",
    "  The slope ( \\frac{dL}{dw} > 0 ) (gradient positive)\n",
    "  ‚Üí the line slopes **up to the right**\n",
    "  ‚Üí to go *downhill*, you move left (decrease `w`)\n",
    "\n",
    "So:\n",
    "[\n",
    "w_{new} = w_{old} - Œ∑¬∑(‚àÇL/‚àÇw)\n",
    "]\n",
    "does exactly that:\n",
    "\n",
    "* If grad is **positive**, subtracting makes `w` smaller ‚Üí move left\n",
    "* If grad is **negative**, subtracting makes `w` bigger ‚Üí move right\n",
    "\n",
    "Every step moves you *toward the bottom of the loss curve*.\n",
    "\n",
    "---\n",
    "\n",
    "# ‚öôÔ∏è 5Ô∏è‚É£ In 2D (w, b) case ‚Äî gradient direction\n",
    "\n",
    "In 2D, the gradient has two components:\n",
    "[\n",
    "\\nabla L =\n",
    "\\begin{bmatrix}\n",
    "‚àÇL/‚àÇw \\\n",
    "‚àÇL/‚àÇb\n",
    "\\end{bmatrix}\n",
    "]\n",
    "\n",
    "That‚Äôs a vector (an arrow) in the (w,b) plane.\n",
    "\n",
    "* The **arrow‚Äôs direction** = steepest uphill\n",
    "* The **negative arrow** = steepest downhill\n",
    "\n",
    "So when you update both:\n",
    "[\n",
    "w := w - Œ∑¬∑(‚àÇL/‚àÇw)\n",
    "]\n",
    "[\n",
    "b := b - Œ∑¬∑(‚àÇL/‚àÇb)\n",
    "]\n",
    "you‚Äôre moving diagonally down toward the valley floor ‚Äî the loss minimum.\n",
    "\n",
    "---\n",
    "\n",
    "# üß† 6Ô∏è‚É£ Visualize it mentally\n",
    "\n",
    "Imagine the loss surface as a bowl:\n",
    "\n",
    "```\n",
    "       L\n",
    "       |\n",
    "     --|--       *\n",
    "   --  |  --    (current w,b)\n",
    "  --   |   --\n",
    " --    |    --\n",
    "-----------------> (w,b plane)\n",
    "```\n",
    "\n",
    "* The * points somewhere on the side of the bowl.\n",
    "* The gradient arrow points directly uphill.\n",
    "* Gradient descent moves in the **opposite** direction.\n",
    "* Each step reduces height (loss).\n",
    "* Eventually, you settle at the bottom (min loss).\n",
    "\n",
    "---\n",
    "\n",
    "# üî¢ 7Ô∏è‚É£ Tiny numeric example (to make it tangible)\n",
    "\n",
    "Say:\n",
    "[\n",
    "L = (w - 3)^2\n",
    "]\n",
    "\n",
    "Then:\n",
    "[\n",
    "‚àÇL/‚àÇw = 2(w - 3)\n",
    "]\n",
    "\n",
    "Case 1Ô∏è‚É£: (w = 5)\n",
    "‚Üí (‚àÇL/‚àÇw = 4) (positive)\n",
    "‚Üí loss increases as w increases\n",
    "‚Üí move left: (w_{new} = 5 - Œ∑√ó4)\n",
    "\n",
    "Case 2Ô∏è‚É£: (w = 1)\n",
    "‚Üí (‚àÇL/‚àÇw = -4) (negative)\n",
    "‚Üí loss increases as w decreases\n",
    "‚Üí move right: (w_{new} = 1 - Œ∑√ó(-4))\n",
    "\n",
    "‚úÖ In both cases, the minus sign ensures you move toward (w = 3),\n",
    "the minimum point of the function.\n",
    "\n",
    "---\n",
    "\n",
    "# üí° 8Ô∏è‚É£ Summary (you nailed the core)\n",
    "\n",
    "| Concept                | Meaning                                       |\n",
    "| ---------------------- | --------------------------------------------- |\n",
    "| Gradient sign (+ or -) | Tells which direction increases loss          |\n",
    "| Negative gradient      | Direction of steepest loss decrease           |\n",
    "| Gradient magnitude     | Tells how steep ‚Äî controls step size          |\n",
    "| Learning rate (Œ∑)      | Controls how far we move along that direction |\n",
    "| Update formula         | Moves us closer to minimum of loss            |\n",
    "\n",
    "So yes ‚Äî the slope gives **both direction and speed** information.\n",
    "We simply follow the *negative gradient* to always step *downhill* toward lower loss.\n",
    "\n",
    "---\n",
    "\n",
    "If you‚Äôd like, I can draw you a **2D loss bowl diagram** (w vs b vs loss)\n",
    "showing how each gradient arrow points and how the optimizer moves step-by-step.\n",
    "Would you like me to make that visual next?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonPractiveEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
